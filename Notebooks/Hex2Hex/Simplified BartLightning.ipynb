{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7632616,"sourceType":"datasetVersion","datasetId":4447546}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install datasets transformers accelerate evaluate wandb nltk pandas pytorch_lightning","metadata":{"id":"PhAeBJfNJsy-","execution":{"iopub.status.busy":"2024-02-28T19:49:18.808354Z","iopub.execute_input":"2024-02-28T19:49:18.808747Z","iopub.status.idle":"2024-02-28T19:49:32.156931Z","shell.execute_reply.started":"2024-02-28T19:49:18.808709Z","shell.execute_reply":"2024-02-28T19:49:32.155543Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom datasets import Dataset, DatasetDict\nfrom transformers import BartTokenizer, BartForConditionalGeneration, T5ForConditionalGeneration, AutoTokenizer\nfrom torch.utils.data import DataLoader\nfrom nltk.metrics.distance import edit_distance\nimport pytorch_lightning as pl\nfrom torch.optim import AdamW\nfrom dataclasses import dataclass\n\n# Set up wandb environment\nos.environ[\"WANDB_PROJECT\"] = \"Seq2SeqZip\"\n\n# Seed for reproducibility\nSEED = 999\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(SEED)\n","metadata":{"id":"hdp0yz7mJsy_","execution":{"iopub.status.busy":"2024-02-28T19:49:32.159609Z","iopub.execute_input":"2024-02-28T19:49:32.160029Z","iopub.status.idle":"2024-02-28T19:49:32.168794Z","shell.execute_reply.started":"2024-02-28T19:49:32.159975Z","shell.execute_reply":"2024-02-28T19:49:32.167612Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Function to load and preprocess dataset\ndef load_and_preprocess_data(filepath):\n    df = pd.read_csv(filepath)[:15000]\n    df[['deflate_hex', 'text_hex', 'text']] += \"</s>\"\n    ds = Dataset.from_pandas(df)\n    ds_train_test = ds.train_test_split(test_size=0.2, seed=SEED)\n    ds_test_dev = ds_train_test['test'].train_test_split(test_size=0.5, seed=SEED)\n    return DatasetDict({\n        'train': ds_train_test['train'],\n        'valid': ds_test_dev['train'],\n        'test': ds_test_dev['test']\n    })\n\nds_splits = load_and_preprocess_data('/kaggle/input/full-dataset/randomized_shorthex2hex.csv')","metadata":{"id":"1nFsQ146JszA","execution":{"iopub.status.busy":"2024-02-28T19:49:32.170223Z","iopub.execute_input":"2024-02-28T19:49:32.170524Z","iopub.status.idle":"2024-02-28T19:49:32.469851Z","shell.execute_reply.started":"2024-02-28T19:49:32.170498Z","shell.execute_reply":"2024-02-28T19:49:32.469062Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"@dataclass\nclass DataCollatorSeq2SeqWithPadding:\n    tokenizer: BartTokenizer\n\n    def __call__(self, dataset_elements):\n        inputs = [x[\"text_hex\"] for x in dataset_elements]\n        outputs = [x[\"deflate_hex\"] for x in dataset_elements]\n        input_features = self.tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length = MAX_SEQ_LEN)\n        output_features = self.tokenizer(outputs, return_tensors=\"pt\", padding=True, truncation=True, max_length = MAX_SEQ_LEN)[\"input_ids\"]\n        output_features[output_features == self.tokenizer.pad_token_id] = -100\n        return {\"input_ids\": input_features[\"input_ids\"], \"attention_mask\": input_features[\"attention_mask\"], \"labels\": output_features}\n","metadata":{"id":"u-PSQfryJszA","execution":{"iopub.status.busy":"2024-02-28T19:49:32.472307Z","iopub.execute_input":"2024-02-28T19:49:32.472681Z","iopub.status.idle":"2024-02-28T19:49:32.480689Z","shell.execute_reply.started":"2024-02-28T19:49:32.472646Z","shell.execute_reply":"2024-02-28T19:49:32.479687Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#MODEL CHOICES: bart-base, bart-large, t5-base\nMODEL = \"t5-base\"\n\nif (MODEL == \"bart-base\"):\n    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n\nelif (MODEL == \"bart-large\"):\n    tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n    model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n\nelse:\n    tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n\ndata_collator = DataCollatorSeq2SeqWithPadding(tokenizer)","metadata":{"id":"PGd5_RNtJszA","execution":{"iopub.status.busy":"2024-02-28T19:49:32.482073Z","iopub.execute_input":"2024-02-28T19:49:32.482512Z","iopub.status.idle":"2024-02-28T19:49:38.620632Z","shell.execute_reply.started":"2024-02-28T19:49:32.482474Z","shell.execute_reply":"2024-02-28T19:49:38.619796Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e9cf375bdf848ed83877ab771575b3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e38dd2d915b4004896ab9ac95df1974"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2aedc94f85f742c68e03f5db5ed0343a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fb36b544d9c44d18815aae6c6109cd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39a4074331f94b1d99c565508e47a8ea"}},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(preds, labels, tokenizer):\n    # Ensure labels with -100 are replaced by pad_token_id\n    labels = torch.where(labels == -100, tokenizer.pad_token_id, labels)\n\n    # Convert tensors to lists for decoding if they're not already in CPU\n    if torch.is_tensor(preds):\n        preds = preds.detach().cpu().tolist()\n    if torch.is_tensor(labels):\n        labels = labels.detach().cpu().tolist()\n\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    distances = [edit_distance(p, l) for p, l in zip(decoded_preds, decoded_labels)]\n    avg_distance = np.mean(distances)\n    count_unzippable = distances.count(0)\n\n    return {\"average_edit_distance\": avg_distance, \"count_unzippable\": count_unzippable}\n","metadata":{"id":"QuX0gGj2JszA","execution":{"iopub.status.busy":"2024-02-28T19:49:38.621748Z","iopub.execute_input":"2024-02-28T19:49:38.622061Z","iopub.status.idle":"2024-02-28T19:49:38.629534Z","shell.execute_reply.started":"2024-02-28T19:49:38.622028Z","shell.execute_reply":"2024-02-28T19:49:38.628547Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16\nMAX_EPOCHS = 5\nLEARNING_RATE = 1e-4\nWEIGHT_DECAY = 1e-2\nMAX_SEQ_LEN = 256\n\nclass Seq2Seq(pl.LightningModule):\n    def __init__(self, tokenizer, model, data_collator):\n        super().__init__()\n        self.tokenizer = tokenizer\n        self.model = model\n        self.data_collator = data_collator\n\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        return self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n\n    def training_step(self, batch, batch_idx):\n        outputs = self.forward(**batch)\n        self.log('train_loss', outputs.loss, prog_bar=True, logger=True)\n        return outputs.loss\n\n    def validation_step(self, batch, batch_idx):\n        outputs = self.forward(**batch)\n        self.log('val_loss', outputs.loss, prog_bar=True, logger=True)\n\n        preds = torch.argmax(outputs.logits, dim=-1)\n        metrics = compute_metrics(preds, batch['labels'], self.tokenizer)\n        for key, value in metrics.items():\n            self.log(f'{key}', value, prog_bar=True, logger=True)\n\n        return outputs.loss\n\n    def test_step(self, batch, batch_idx):\n        outputs = self.forward(**batch)\n        self.log('test_loss', outputs.loss, prog_bar=True, logger=True)\n        \n        preds = torch.argmax(outputs.logits, dim=-1)\n        metrics = compute_metrics(preds, batch['labels'], self.tokenizer)\n        \n        for key, value in metrics.items():\n            self.log(f'{key}', value, prog_bar=True, logger=True)\n        return outputs.loss\n\n    def configure_optimizers(self):\n        # Directly use learning rate and weight decay values here\n        return AdamW(self.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n\ntrainer = pl.Trainer(\n    precision='16-mixed',\n    max_epochs=MAX_EPOCHS,\n    enable_progress_bar=True,\n)\n\ntrain_dataloader = DataLoader(ds_splits[\"train\"], batch_size=BATCH_SIZE, shuffle = True, collate_fn=data_collator, num_workers = 3)\nvalid_dataloader = DataLoader(ds_splits[\"valid\"], batch_size=BATCH_SIZE, shuffle = False, collate_fn=data_collator, num_workers = 3)\ntest_dataloader = DataLoader(ds_splits[\"test\"], batch_size=BATCH_SIZE, shuffle = False, collate_fn=data_collator, num_workers = 3)\n\nseq2seq_model = Seq2Seq(tokenizer, model, data_collator)\ntrainer.fit(seq2seq_model, train_dataloader, valid_dataloader)\n\ntrainer.test(seq2seq_model, test_dataloader)","metadata":{"id":"mvEo6XxsJszA","execution":{"iopub.status.busy":"2024-02-28T19:49:38.631136Z","iopub.execute_input":"2024-02-28T19:49:38.631538Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d31833b6581e46b394764400881a91fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c841f5d6bf430eac0ba4e703e6b034"}},"metadata":{}}]}]}