{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkKtT4GK-7y1"
      },
      "source": [
        "# Imports and installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-14T14:12:47.102895Z",
          "iopub.status.busy": "2024-03-14T14:12:47.102006Z"
        },
        "id": "woNI1XG6H-Bb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets transformers accelerate evaluate wandb nltk pandas lightning bitsandbytes peft sentencepiece trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBg7g-c1A7kR",
        "outputId": "4a9546df-b7f9-4475-cb47-adb81684cb79",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Seed set to 124\n",
            "INFO:lightning.fabric.utilities.seed:Seed set to 124\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, T5ForConditionalGeneration, AutoTokenizer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
        "from peft import prepare_model_for_kbit_training, LoraConfig, get_peft_model\n",
        "from trl import SFTTrainer\n",
        "import lightning as L\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "SEED = 124\n",
        "\n",
        "#DATA USED\n",
        "SHORT = False\n",
        "RANDOMIZED_SHORT = True\n",
        "MEDIUM = False\n",
        "\n",
        "MAX_SEQ_LEN = 512 if MEDIUM else 256\n",
        "\n",
        "#MODEL USED\n",
        "FEEDFORWARD = True\n",
        "FEEDFORWARD_WITH_ATTENTION = False\n",
        "CONV1D = False\n",
        "RNN = False\n",
        "SEQ2SEQ = False\n",
        "\n",
        "#MODEL CHOICES FOR SEQ2SEQ: bart-base, bart-large, t5-base\n",
        "MODEL = \"bart-base\"\n",
        "\n",
        "#RNN MODELS AND HYPERPARAMETERS\n",
        "BIDIRECTIONAL = False\n",
        "RNN_TYPE = 'RNN'  # Options: 'LSTM', 'GRU', 'RNN'\n",
        "\n",
        "#HYPERPARAMETERS\n",
        "EMBED_DIM = 128\n",
        "HIDDEN_DIM = 512\n",
        "LEARNING_RATE = 5e-4\n",
        "DROPOUT_RATE = 0.5\n",
        "NUM_HEADS = 4\n",
        "NUM_LAYERS = 4\n",
        "WEIGHT_DECAY = 0.01\n",
        "MAX_EPOCHS = 1\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "L.seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9xAcbOfEyxw",
        "outputId": "a6f2efda-7dac-4330-fb24-c657f67a71b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK\n"
          ]
        }
      ],
      "source": [
        "models_values = [FEEDFORWARD, FEEDFORWARD_WITH_ATTENTION, CONV1D, RNN, SEQ2SEQ]\n",
        "num_true = sum(models_values)\n",
        "\n",
        "# Check if only one value is True\n",
        "if num_true == 1:\n",
        "    print(\"OK\")\n",
        "else:\n",
        "    print(\"ATTENTION! SELECT ONLY ONE MODEL TO RUN\")\n",
        "    ## Using this so that is more than one model is selected the execution does not continue\n",
        "    print(UNDEFINED_VARIABLE_TO_LET_THE_NOTEBOOK_CRASH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afxIsaS-8AhR",
        "outputId": "9908d579-4ed7-4482-bae8-e89e8d4270f4",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwbZbYZN_05Z"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y5zOqIHW-mTV"
      },
      "outputs": [],
      "source": [
        "## Mapping from token to id used for encoding hexadecimal strings\n",
        "token2id = {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9, \"a\": 10, \"b\": 11, \"c\": 12, \"d\": 13, \"e\": 14, \"f\": 15, \"P\":16, \"S\": 17, \"E\":18 }\n",
        "def create_id2token_vocab(token_to_id):\n",
        "    id2token = {}\n",
        "    for token, id in token_to_id.items():\n",
        "        id2token[id] = token\n",
        "\n",
        "    return id2token\n",
        "\n",
        "id2token = create_id2token_vocab(token2id)\n",
        "\n",
        "## INIZIALIZE OUTPUT DIM NOW THAT I KNOW THE LENGTH OF THE TOKEN2ID DICTIONARY\n",
        "OUTPUT_DIM = len(token2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41-sA-aM-G7v",
        "outputId": "5da6d55a-faae-4071-c859-407c755ada81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-03-29 17:39:00--  https://github.com/Tommaiberone/Zip-generation/raw/main/Datasets/datasets.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Tommaiberone/Zip-generation/main/Datasets/datasets.zip [following]\n",
            "--2024-03-29 17:39:00--  https://raw.githubusercontent.com/Tommaiberone/Zip-generation/main/Datasets/datasets.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8767992 (8.4M) [application/zip]\n",
            "Saving to: ‘/content/datasets.zip’\n",
            "\n",
            "/content/datasets.z 100%[===================>]   8.36M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2024-03-29 17:39:00 (131 MB/s) - ‘/content/datasets.zip’ saved [8767992/8767992]\n",
            "\n",
            "Archive:  /content/datasets.zip\n",
            "  inflating: mediumhex2hex.csv       \n",
            "  inflating: randomized_shorthex2hex.csv  \n",
            "  inflating: shorthex2hex.csv        \n"
          ]
        }
      ],
      "source": [
        "!wget -O /content/datasets.zip https://github.com/Tommaiberone/Zip-generation/raw/main/Datasets/datasets.zip\n",
        "!unzip -o /content/datasets.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f-sQt-E_Arl2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if SHORT:\n",
        "  df = pd.read_csv('/content/mediumhex2hex.csv')\n",
        "elif RANDOMIZED_SHORT:\n",
        "  df = pd.read_csv('/content/randomized_shorthex2hex.csv')\n",
        "elif MEDIUM:\n",
        "  df = pd.read_csv('/content/shorthex2hex.csv')\n",
        "\n",
        "\n",
        "df = df[:40960]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aT-D7npnp_3p",
        "outputId": "d4b9d965-f2c9-4178-8a72-ec5c05b5ac6b",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40960,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40690,\n        \"samples\": [\n          \"be relegated to subserviant\",\n          \"of Power Rangers contains\",\n          \"her in whatever situation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_hex\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40690,\n        \"samples\": [\n          \"62652072656c65676174656420746f207375627365727669616e74\",\n          \"6f6620506f7765722052616e6765727320636f6e7461696e73\",\n          \"68657220696e20776861746576657220736974756174696f6e\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"deflate_hex\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40690,\n        \"samples\": [\n          \"789c4b4a55284acd494d4f2c494d5128c957282e4d2a4e2d2acb4ccc2b01008d3f0a6e\",\n          \"789ccb4f5308c82f4f2d52084acc4b4f2d2a5648cecf2b49cccc2b0600769f0974\",\n          \"789ccb482d52c8cc5328cf482c492d03b28b334b4a134b32f3f3007a4d09bd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f84b758f-7cf3-419c-9ab2-a6bc7ffb74bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_hex</th>\n",
              "      <th>deflate_hex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this is not a</td>\n",
              "      <td>74686973206973206e6f742061</td>\n",
              "      <td>789c2bc9c82c5600a2bcfc1285440021fe04a7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>and gives a comforting,</td>\n",
              "      <td>616e64206769766573206120636f6d666f7274696e672c</td>\n",
              "      <td>789c4bcc4b5148cf2c4b2d56485448cecf4dcb2f2ac9cc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>killer). While some may</td>\n",
              "      <td>6b696c6c6572292e205768696c6520736f6d65206d6179</td>\n",
              "      <td>789ccbceccc9492dd2d45308cfc8cc495528cecf4d55c8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>in his closet &amp;</td>\n",
              "      <td>696e2068697320636c6f7365742026</td>\n",
              "      <td>789ccbcc53c8c82c5648cec92f4e2d515003002b16052c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>film to watch. Mr.</td>\n",
              "      <td>66696c6d20746f2077617463682e204d722e</td>\n",
              "      <td>789c4bcbccc95528c957284f2c49ced053f02dd203003d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f84b758f-7cf3-419c-9ab2-a6bc7ffb74bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f84b758f-7cf3-419c-9ab2-a6bc7ffb74bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f84b758f-7cf3-419c-9ab2-a6bc7ffb74bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0df1cade-1ffe-4529-ae1f-431602b26a59\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0df1cade-1ffe-4529-ae1f-431602b26a59')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0df1cade-1ffe-4529-ae1f-431602b26a59 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                      text                                        text_hex  \\\n",
              "0            this is not a                      74686973206973206e6f742061   \n",
              "1  and gives a comforting,  616e64206769766573206120636f6d666f7274696e672c   \n",
              "2  killer). While some may  6b696c6c6572292e205768696c6520736f6d65206d6179   \n",
              "3          in his closet &                  696e2068697320636c6f7365742026   \n",
              "4       film to watch. Mr.            66696c6d20746f2077617463682e204d722e   \n",
              "\n",
              "                                         deflate_hex  \n",
              "0             789c2bc9c82c5600a2bcfc1285440021fe04a7  \n",
              "1  789c4bcc4b5148cf2c4b2d56485448cecf4dcb2f2ac9cc...  \n",
              "2  789ccbceccc9492dd2d45308cfc8cc495528cecf4d55c8...  \n",
              "3     789ccbcc53c8c82c5648cec92f4e2d515003002b16052c  \n",
              "4  789c4bcbccc95528c957284f2c49ced053f02dd203003d...  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if RNN:\n",
        "  df['text_hex'] = 'S' + df['text_hex'] + 'E'\n",
        "  df['deflate_hex'] = 'S' + df['deflate_hex'] + 'E'\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVUV1WDuvi7G"
      },
      "source": [
        "Instead of using the standard \\<EOS> and \\<SOS> tags we're using the letter S and E since they are not present in the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LE9OmLvsIdlf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if SEQ2SEQ:\n",
        "    df = df[:15000]\n",
        "    df[['deflate_hex', 'text_hex', 'text']] += \"</s>\"\n",
        "\n",
        "ds = Dataset.from_pandas(df)\n",
        "ds_train_test = ds.train_test_split(test_size=0.2, seed=SEED)\n",
        "ds_test_dev = ds_train_test['test'].train_test_split(test_size=0.5, seed=SEED)\n",
        "ds_splits = DatasetDict({\n",
        "    'train': ds_train_test['train'],\n",
        "    'valid': ds_test_dev['train'],\n",
        "    'test': ds_test_dev['test']\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBdD8nIBrL30"
      },
      "source": [
        "## Data tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ul8yGNNv9zKn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "if SEQ2SEQ:\n",
        "    if (MODEL == \"bart-base\"):\n",
        "        tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "        model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
        "\n",
        "    elif (MODEL == \"bart-large\"):\n",
        "        tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
        "        model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\")\n",
        "\n",
        "    else:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "        model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VF82QijJt4nw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "\n",
        "    if FEEDFORWARD or FEEDFORWARD_WITH_ATTENTION or CONV1D:\n",
        "\n",
        "        texts = [elem['text_hex'] for elem in batch]\n",
        "        encoded_hexs = [[token2id[char] for char in text] for text in texts]\n",
        "\n",
        "        outputs = [elem['deflate_hex'] for elem in batch]\n",
        "        encoded_outputs = [[token2id[char] for char in output] for output in outputs]\n",
        "\n",
        "        ## Pad the sequences to MAX_SEQ_LEN chars with the padding token\n",
        "        padded_hex = [torch.Tensor(encoded_hex + [token2id[\"P\"]] * (MAX_SEQ_LEN - len(encoded_hex))) for encoded_hex in encoded_hexs]\n",
        "        padded_outputs = [torch.Tensor(encoded_output + [token2id[\"P\"]] * (MAX_SEQ_LEN - len(encoded_output))) for encoded_output in encoded_outputs]\n",
        "\n",
        "        ## Stack the sequences\n",
        "        padded_hex = torch.stack(padded_hex).long()\n",
        "        padded_outputs = torch.stack(padded_outputs).long()\n",
        "\n",
        "\n",
        "        return {\n",
        "            'inputs': padded_hex,\n",
        "            'outputs': padded_outputs\n",
        "        }\n",
        "\n",
        "    elif RNN:\n",
        "\n",
        "        ## Dynamic padding for RNNs\n",
        "        def pad_sequences(sequences, maxlen, value=token2id['P']):\n",
        "            padded_sequences = []\n",
        "            for sequence in sequences:\n",
        "                padded_sequence = sequence[:maxlen]\n",
        "                padded_sequence.extend([value] * (maxlen - len(padded_sequence)))\n",
        "\n",
        "                padded_sequence = sequence +  [value] * (maxlen - len(sequence))\n",
        "                padded_sequences.append(padded_sequence)\n",
        "\n",
        "            return padded_sequences\n",
        "\n",
        "\n",
        "        texts = [elem['text_hex'] for elem in batch]\n",
        "        encoded_hex = [[token2id[x] for x in hex] for hex in texts]\n",
        "\n",
        "\n",
        "        outputs = [elem['deflate_hex'] for elem in batch]\n",
        "        encoded_outputs = [[token2id[x] for x in hex] for hex in outputs]\n",
        "\n",
        "\n",
        "        maxlen = 0\n",
        "        for seq in encoded_hex:\n",
        "            if len(seq) > maxlen:\n",
        "                maxlen = len(seq)\n",
        "        for seq in encoded_outputs:\n",
        "            if len(seq) > maxlen:\n",
        "                maxlen = len(seq)\n",
        "\n",
        "        padded_encoded_hex = pad_sequences(encoded_hex, maxlen)\n",
        "        padded_encoded_outputs = pad_sequences(encoded_outputs, maxlen)\n",
        "\n",
        "\n",
        "        return {\n",
        "            'inputs': torch.tensor(padded_encoded_hex),\n",
        "            \"outputs\": torch.tensor(padded_encoded_outputs)\n",
        "        }\n",
        "\n",
        "    elif SEQ2SEQ:\n",
        "        inputs = [x[\"text_hex\"] for x in batch]\n",
        "        outputs = [x[\"deflate_hex\"] for x in batch]\n",
        "        input_features = tokenizer(inputs, \n",
        "                                   return_tensors=\"pt\", \n",
        "                                   padding=True, \n",
        "                                   truncation=True, \n",
        "                                   max_length=MAX_SEQ_LEN)\n",
        "        \n",
        "        output_features = tokenizer(outputs,\n",
        "                                    return_tensors=\"pt\", \n",
        "                                    padding=True, \n",
        "                                    truncation=True, \n",
        "                                    max_length=MAX_SEQ_LEN)[\"input_ids\"]\n",
        "        \n",
        "        output_features[output_features == tokenizer.pad_token_id] = -100\n",
        "        return {\"input_ids\": input_features[\"input_ids\"], \n",
        "                \"attention_mask\": input_features[\"attention_mask\"], \n",
        "                \"labels\": output_features}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpUMB8N1_l5b"
      },
      "source": [
        "## Initializing dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imBbEVs39zKo",
        "outputId": "cbf24055-041a-4d1c-a45c-97b4843f15bc",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "train_dataloader = DataLoader(ds_splits['train'],\n",
        "                               batch_size=BATCH_SIZE, \n",
        "                               shuffle=True, \n",
        "                               collate_fn=collate_fn,\n",
        "                               num_workers = 3)\n",
        "\n",
        "val_dataloader = DataLoader(ds_splits['valid'], \n",
        "                            batch_size=BATCH_SIZE, \n",
        "                            shuffle=False, \n",
        "                            collate_fn=collate_fn, \n",
        "                            num_workers = 3)\n",
        "\n",
        "test_dataloader = DataLoader(ds_splits['test'],\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False, \n",
        "                             collate_fn=collate_fn,\n",
        "                             num_workers = 3)\n",
        "\n",
        "torch.set_printoptions(profile=\"full\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGAexQaB_rIU"
      },
      "source": [
        "### Evaluation functions\n",
        "\n",
        "We're using the nltk library to compute the edit distance (Levenshtein distance) between the predicted string and the target/gold string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9Dj2fBhI9zKo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.metrics.distance import edit_distance\n",
        "\n",
        "def decode_output(output):\n",
        "    return ''.join([id2token[int(id)] for id in output])\n",
        "\n",
        "def decode_input(input):\n",
        "    return ''.join([id2token[int(id)] for id in input])\n",
        "\n",
        "## function used to compute metrics for Seq2Seq models (bart/t5)\n",
        "def compute_seq2seq_metrics(preds, labels, tokenizer):\n",
        "    # Ensure labels with -100 are replaced by pad_token_id\n",
        "    labels = torch.where(labels == -100, tokenizer.pad_token_id, labels)\n",
        "\n",
        "    # Convert tensors to lists and detach them from cuda\n",
        "    if torch.is_tensor(preds):\n",
        "        preds = preds.detach().cpu().tolist()\n",
        "    if torch.is_tensor(labels):\n",
        "        labels = labels.detach().cpu().tolist()\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    distances = [edit_distance(p, l) for p, l in zip(decoded_preds, decoded_labels)]\n",
        "    avg_distance = np.mean(distances)\n",
        "    count_unzippable = distances.count(0)\n",
        "\n",
        "    return {\"average_edit_distance\": avg_distance, \"count_unzippable\": count_unzippable}\n",
        "\n",
        "## function used to compute metrics for all the other models\n",
        "def evaluate(_device, _print, _training):\n",
        "\n",
        "    model.eval()\n",
        "    total_distance = 0\n",
        "    total = 0\n",
        "\n",
        "    distances_list = []\n",
        "\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "\n",
        "        if FEEDFORWARD or FEEDFORWARD_WITH_ATTENTION or CONV1D:\n",
        "            x = batch[\"inputs\"].to(_device)\n",
        "            y = batch[\"outputs\"].to(_device)\n",
        "\n",
        "            y_hat = model(x, y)\n",
        "            y_hat = torch.argmax(y_hat, dim=-1)\n",
        "\n",
        "            output = decode_output(y[0])\n",
        "            output_hat = decode_output(y_hat[0])\n",
        "\n",
        "            output = [x for x in output if x != \"P\"]\n",
        "            output_hat = [x for x in output_hat if x != \"P\"]\n",
        "\n",
        "            distance = edit_distance(output, output_hat)\n",
        "\n",
        "        elif RNN:\n",
        "            x = batch[\"inputs\"].transpose(0,1).to(_device)\n",
        "            y = batch[\"outputs\"].transpose(0,1).to(_device)\n",
        "\n",
        "            y_hat = model(x, y)\n",
        "            y_hat = torch.argmax(y_hat, dim=-1)\n",
        "\n",
        "            y = y.transpose(0,1)\n",
        "            y_hat = y_hat.transpose(0,1)\n",
        "\n",
        "            assert len(y) == len(y_hat)\n",
        "\n",
        "            for i in range(len(y)):\n",
        "                output = decode_output(y[i])\n",
        "                output_hat = decode_output(y_hat[i])\n",
        "\n",
        "                ## Remove padding\n",
        "                output = [x for x in output if x != \"P\"]\n",
        "                output_hat = [x for x in output_hat if x != \"P\"]\n",
        "\n",
        "                ## Save the index of the first EOS token, if any. Else consider all the string\n",
        "                first_eos_index = len(output_hat)\n",
        "                for i in range(len(output_hat)):\n",
        "                    if output_hat[i] == \"E\":\n",
        "                        first_eos_index = i\n",
        "                        break\n",
        "\n",
        "                # Remove SOS token\n",
        "                output = output[1:]\n",
        "                output_hat = output_hat[1:first_eos_index]\n",
        "\n",
        "                ## Compute distance\n",
        "                distance = edit_distance(output, output_hat)\n",
        "                distances_list.append(distance)\n",
        "\n",
        "        if _print:\n",
        "            print(f\"output = {output}\")\n",
        "            print(f\"output_hat = {output_hat}\")\n",
        "\n",
        "        total_distance += distance\n",
        "        total += 1\n",
        "\n",
        "        if distance == 0:\n",
        "            print(f\"DISTANCE = 0!\")\n",
        "            print(f\"output = {output}\")\n",
        "            print(f\"output_hat = {output_hat}\")\n",
        "\n",
        "        if _training:\n",
        "            return total_distance/total\n",
        "\n",
        "    return (total_distance/total, distances_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IDexjaaCS1x"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8a2nJxCC9zKo",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "## In this class there are the following models:\n",
        "## 1. Vanilla FeedForward\n",
        "## 2. FeedForward with Attention\n",
        "## 3. Conv1D\n",
        "## You can switch between those models using the parameters present in the first cell of this Notebook\n",
        "\n",
        "class FeedForward(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, input_dim=MAX_SEQ_LEN, embed_dim = EMBED_DIM, hidden_dim=HIDDEN_DIM, \n",
        "                 output_dim=OUTPUT_DIM, learning_rate=LEARNING_RATE, dropout_rate=DROPOUT_RATE, \n",
        "                 bidirectional=BIDIRECTIONAL, num_layers=NUM_LAYERS, optimizer_type=AdamW, \n",
        "                 scheduler_type=StepLR, scheduler_step_size=5, scheduler_gamma=0.1):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        if FEEDFORWARD or FEEDFORWARD_WITH_ATTENTION:\n",
        "            self.embed = nn.Embedding(input_dim, embed_dim)\n",
        "            self.positional_embeddings = nn.Parameter(torch.zeros(BATCH_SIZE, input_dim, embed_dim))\n",
        "            nn.init.normal_(self.positional_embeddings, mean=0, std=embed_dim ** -0.5)  # Initialize positional embeddings\n",
        "            self.self_attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=NUM_HEADS, \n",
        "                                                        dropout=dropout_rate, batch_first = True)\n",
        "            self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
        "            self.norm1 = nn.LayerNorm(hidden_dim)\n",
        "            self.dropout = nn.Dropout(dropout_rate)\n",
        "            self.fc2 = nn.Linear(hidden_dim, hidden_dim//2)\n",
        "            self.norm2 = nn.LayerNorm(hidden_dim//2)\n",
        "            self.fc3 = nn.Linear(hidden_dim//2, output_dim)\n",
        "\n",
        "        elif CONV1D:\n",
        "\n",
        "            # Embedding layer to transform dictionary indices into dense vectors\n",
        "            self.embedding = nn.Embedding(num_embeddings=input_dim, embedding_dim=embed_dim)\n",
        "\n",
        "            # Convolutional layers\n",
        "            self.conv1 = nn.Conv1d(in_channels=embed_dim, out_channels=embed_dim, kernel_size=3, padding=1)\n",
        "\n",
        "            # Fully connected layers for classification\n",
        "            self.fc1 = nn.Linear(embed_dim, embed_dim)\n",
        "            self.fc2 = nn.Linear(embed_dim, output_dim)\n",
        "\n",
        "            # Hyperparameters\n",
        "            self.learning_rate = learning_rate\n",
        "\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x, target, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        if FEEDFORWARD or FEEDFORWARD_WITH_ATTENTION:\n",
        "\n",
        "            # Embedding\n",
        "            x = self.embed(x)  # Shape: [Batch, Seq_len, Embed_dim]\n",
        "\n",
        "            if (FEEDFORWARD_WITH_ATTENTION):\n",
        "\n",
        "                # Add positional embeddings\n",
        "                positions = self.positional_embeddings\n",
        "                x = x + positions\n",
        "\n",
        "                # Self-attention\n",
        "                attn_output, _ = self.self_attention(x, x, x)\n",
        "\n",
        "                x = torch.relu(self.norm1(self.fc1(attn_output)))\n",
        "\n",
        "            else:\n",
        "                x = torch.relu(self.norm1(self.fc1(x)))\n",
        "\n",
        "            x = self.dropout(x)\n",
        "            x = torch.relu(self.norm2(self.fc2(x)))\n",
        "            x = self.fc3(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "        elif CONV1D:\n",
        "\n",
        "            # Embedding layer\n",
        "            x = self.embedding(x)\n",
        "\n",
        "            # Transpose from (batch_size, sequence_length, embedding_dim) to (batch_size, embedding_dim, sequence_length)\n",
        "            x = x.permute(0, 2, 1)\n",
        "\n",
        "            x = torch.relu(self.conv1(x))\n",
        "\n",
        "            x = x.permute(0, 2, 1)\n",
        "\n",
        "            x = torch.relu(self.fc1(x))\n",
        "\n",
        "            x = self.fc2(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = self.hparams.optimizer_type(self.parameters(), lr=self.hparams.learning_rate)\n",
        "        scheduler = self.hparams.scheduler_type(optimizer, step_size=self.hparams.scheduler_step_size, gamma=self.hparams.scheduler_gamma)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "    def step(self, batch):\n",
        "        if (FEEDFORWARD or FEEDFORWARD_WITH_ATTENTION or CONV1D):\n",
        "            x = batch[\"inputs\"]\n",
        "            y = batch[\"outputs\"]\n",
        "            y = y.view(y.shape[0] * y.shape[1])\n",
        "            y_hat = self(x, y)\n",
        "            y_hat = y_hat.view(y_hat.shape[0] * y_hat.shape[1], y_hat.shape[2])\n",
        "\n",
        "        loss = self.loss(y_hat, y)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss = self.step(batch)\n",
        "        self.log('train_loss', loss, prog_bar = True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.step(batch)\n",
        "        self.log('val_loss', loss, prog_bar = True)\n",
        "        return loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm98JZPQDOhD"
      },
      "source": [
        "# Recurrent Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "49CQjkYrDQg7"
      },
      "outputs": [],
      "source": [
        "class Recurrent(pl.LightningModule):\n",
        "      def __init__(self, input_dim=MAX_SEQ_LEN, embed_dim = EMBED_DIM, hidden_dim=HIDDEN_DIM, output_dim=OUTPUT_DIM, learning_rate=LEARNING_RATE,\n",
        "                 dropout_rate=DROPOUT_RATE, bidirectional=BIDIRECTIONAL, num_layers=NUM_LAYERS, optimizer_type=AdamW, scheduler_type=StepLR,\n",
        "                 scheduler_step_size=5, scheduler_gamma=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.rnn_type = RNN_TYPE\n",
        "        self.embedding = nn.Embedding(output_dim, embed_dim, padding_idx=token2id['P'])\n",
        "\n",
        "        if self.rnn_type == 'LSTM':\n",
        "          rnn_cell = nn.LSTM\n",
        "        elif self.rnn_type == 'GRU':\n",
        "          rnn_cell = nn.GRU\n",
        "        else:  # Default to RNN if neither LSTM nor GRU is selected\n",
        "          rnn_cell = nn.RNN\n",
        "\n",
        "        self.encoder_rnn = rnn_cell(embed_dim, hidden_dim, num_layers=num_layers, \n",
        "                                    bidirectional=bidirectional, \n",
        "                                    dropout=dropout_rate if num_layers > 1 else 0)\n",
        "        \n",
        "        self.decoder_rnn = rnn_cell(embed_dim, hidden_dim, num_layers=num_layers, \n",
        "                                    bidirectional=bidirectional, \n",
        "                                    dropout=dropout_rate if num_layers > 1 else 0)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.output_dim = output_dim\n",
        "        self.linear = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        self.loss = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "      def forward(self, x, target, teacher_forcing_ratio=0.5):\n",
        "        target_len = target.shape[0]\n",
        "        batch_size = target.shape[1]\n",
        "        target_vocab_size = self.output_dim\n",
        "\n",
        "        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(self.device)\n",
        "\n",
        "        x = self.dropout(self.embedding(x))\n",
        "        rnn_output, h = self.encoder_rnn(x)\n",
        "\n",
        "        x = target[0]\n",
        "        for t in range(1, target_len):\n",
        "          x = self.dropout(self.embedding(x.unsqueeze(0)))\n",
        "          out, h = self.decoder_rnn(x, h if self.rnn_type in ['LSTM', 'GRU'] else None)\n",
        "          predictions = self.linear(out)\n",
        "          predictions = predictions.squeeze(0)\n",
        "          outputs[t] = predictions\n",
        "          pred = predictions.argmax(1)\n",
        "          x = target[t] if random.random() < teacher_forcing_ratio else pred\n",
        "\n",
        "        return outputs\n",
        "\n",
        "      def configure_optimizers(self):\n",
        "        optimizer = self.hparams.optimizer_type(self.parameters(), lr=self.hparams.learning_rate)\n",
        "        scheduler = self.hparams.scheduler_type(optimizer, step_size=self.hparams.scheduler_step_size, \n",
        "                                                gamma=self.hparams.scheduler_gamma)\n",
        "        return [optimizer], [scheduler]\n",
        "\n",
        "      def step(self, batch):\n",
        "        inputs, targets = batch['inputs'], batch['outputs']\n",
        "        inputs = inputs.transpose(0, 1)\n",
        "        targets = targets.transpose(0, 1)\n",
        "\n",
        "        output = self(inputs, targets)\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        y_hat = output.reshape(-1, output_dim)\n",
        "        y = targets.reshape(-1)\n",
        "\n",
        "        loss = self.loss(y_hat, y)\n",
        "        return loss\n",
        "\n",
        "      def training_step(self, batch, batch_idx):\n",
        "          loss = self.step(batch)\n",
        "          self.log('train_loss', loss, prog_bar = True)\n",
        "          return loss\n",
        "\n",
        "      def validation_step(self, batch, batch_idx):\n",
        "          loss = self.step(batch)\n",
        "          self.log('val_loss', loss, prog_bar = True)\n",
        "          return loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Im389s_SCa_J"
      },
      "source": [
        "# Seq2Seq Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kqRR8xEaCZmm"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq(pl.LightningModule):\n",
        "    def __init__(self, tokenizer, model):\n",
        "        super().__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None, labels=None):\n",
        "        return self.model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self.forward(**batch)\n",
        "        self.log('train_loss', outputs.loss, prog_bar=True, logger=True)\n",
        "        return outputs.loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        outputs = self.forward(**batch)\n",
        "        self.log('val_loss', outputs.loss, prog_bar=True, logger=True)\n",
        "\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        metrics = compute_seq2seq_metrics(preds, batch['labels'], self.tokenizer)\n",
        "        for key, value in metrics.items():\n",
        "            self.log(f'{key}', value, prog_bar=True, logger=True)\n",
        "\n",
        "        return outputs.loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        outputs = self.forward(**batch)\n",
        "        self.log('test_loss', outputs.loss, prog_bar=True, logger=True)\n",
        "\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        metrics = compute_seq2seq_metrics(preds, batch['labels'], self.tokenizer)\n",
        "\n",
        "        for key, value in metrics.items():\n",
        "            self.log(f'{key}', value, prog_bar=True, logger=True)\n",
        "        return outputs.loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "        scheduler = {\n",
        "            'scheduler': get_linear_schedule_with_warmup(optimizer, num_warmup_steps=500, num_training_steps=10000),\n",
        "            'name': 'learning_rate',\n",
        "            'interval': 'step',\n",
        "            'frequency': 1\n",
        "        }\n",
        "        return [optimizer], [scheduler]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfMYpWq3EVEL"
      },
      "source": [
        "# Train!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0f6ad78f8a64499ba618004a60df6697",
            "60c7f11ac08846f99d73a916496cb92c",
            "7883a2398945478eaaeb96d56ee38b84",
            "5933849bbd3c428c81082dbce63d18ff",
            "aec78a401d0f40d599bc72d34ed6f7e8",
            "cd34f80f92bf4c759a994a45ad9d0574",
            "d6caea833dab45669f8eefb5f8335e22",
            "88ae069397e64ef8955d657581ccfff3",
            "5af6274fdeb7460dba6b5fb21ed9dda1",
            "62ec2038927d4499bb7aac028ba397d5",
            "36b51407c0f141da91e895e142921b6d",
            "56bf8723fc664d098c9f2c487a75ec13",
            "021dfb1e492448e1b4a817f573493805",
            "20d38a1bc02c4c7aa7d82bca56bfda83",
            "df09131b522745ccb8b0656989d9f2a8",
            "b84e86cc8b1a4b81995a04bcf2cdb1ad",
            "d013ebb2b0c040c9b48e3ea69a970f78",
            "a8912df1b80a47b3b23e11bc0d09016e",
            "6373de30df414018966cdf60f27489b7",
            "ca1602a0c3844f22aabb9e0a9ef27c37",
            "894026c6b2da4a39955527d5aeb5e85f",
            "c170728a5c984cca85b0a5d42e4a2559",
            "8b8fd0e718d24812a67d356c6006fe71",
            "0de15e901b9e447c935d03f3abbb7181",
            "076d745cfeb74e1b91650d911bcbf61f",
            "4a0a6fc2c1c64e32a9d38816703bf8ae",
            "61bedbd86957498895a0e2bf2f7681e6",
            "e66adf27f81e45af8f99afb63355fcee",
            "5ddf57a4a7d24902b5f852453231a5c3",
            "7aadecf205f04732bcd4c9c48ac9c2c6",
            "0447e03163294685a7c68bb092bb3f39",
            "fead76e6089246a4acfe2353492ffb50",
            "9197deb1965648d6a6f250e0b3161ef9"
          ]
        },
        "id": "Czx7bfJJEV-y",
        "outputId": "44468587-3222-46eb-e4a1-33e5d0587200"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name           | Type               | Params\n",
            "------------------------------------------------------\n",
            "0 | embed          | Embedding          | 32.8 K\n",
            "1 | self_attention | MultiheadAttention | 66.0 K\n",
            "2 | fc1            | Linear             | 66.0 K\n",
            "3 | norm1          | LayerNorm          | 1.0 K \n",
            "4 | dropout        | Dropout            | 0     \n",
            "5 | fc2            | Linear             | 131 K \n",
            "6 | norm2          | LayerNorm          | 512   \n",
            "7 | fc3            | Linear             | 4.9 K \n",
            "8 | loss           | CrossEntropyLoss   | 0     \n",
            "  | other params   | n/a                | 4.2 M \n",
            "------------------------------------------------------\n",
            "4.5 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.5 M     Total params\n",
            "17.988    Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f6ad78f8a64499ba618004a60df6697",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56bf8723fc664d098c9f2c487a75ec13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b8fd0e718d24812a67d356c6006fe71",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=1` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output = ['7', '8', '9', 'c', '4', 'b', '4', 'e', 'c', 'c', '5', '3', 'c', '8', 'c', 'e', 'c', 'b', '2', 'f', '5', '7', '2', '8', 'c', '9', '4', '8', '2', 'c', '0', '1', '1', '2', '9', '9', 'c', '5', '0', '0', '3', 'e', 'd', 'a', '0', '6', 'b', 'b']\n",
            "output_hat = ['4', '8', '4', '8', '4', 'c', 'c', 'c', '4', '8', '4', 'c', '4', 'c', 'c', 'c', 'c', 'c', 'c', '8', '4', 'c', '4', '8', 'c', '8', 'c', 'c', 'c', '8', '4', 'c', '4', '8', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', '4', 'b', 'c', 'c', '4', 'b', '5', '1', 'c', '8', '4', 'b', 'c', 'c', '2', 'c', '4', 'b', 'd', '5', '5', '1', '2', '8', 'c', '9', '4', '8', '5', '5', 'c', '8', 'c', 'f', '4', 'b', '0', '5', '0', '0', '3', 'c', '6', '2', '0', '6', '5', '6']\n",
            "output_hat = ['4', '8', '4', 'c', '4', '8', 'c', 'c', '4', 'c', '4', '8', '4', '8', 'c', '4', '4', '8', 'c', '8', 'c', 'c', 'c', '8', '4', 'c', '4', '8', 'c', 'c', '4', 'c', '4', 'c', '4', '8']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', 'c', '9', '4', '8', '5', '5', '4', '8', 'c', 'b', '2', 'c', '2', 'a', '2', 'e', '5', '1', '4', '8', '2', 'd', 'c', '8', '2', 'c', 'c', 'e', '4', 'f', '4', '9', '5', '5', '2', '8', '4', 'e', '4', 'd', 'c', 'd', '2', 'd', '0', '6', '0', '0', '6', '8', 'b', '9', '0', '8', 'd', '0']\n",
            "output_hat = ['c', '8', '4', 'c', '4', '8', 'c', 'c', '4', '4', '4', '8', 'c', 'c', 'c', '8', 'c', '8', 'c', 'c', '4', '8', 'c', 'c', '4', '8', 'c', '8', '4', 'c', '4', '8', '4', '8', 'c', 'c', 'c', '8', '4', '8', '4', '8', '4', '8', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', '4', 'f', '5', '3', '4', '8', '2', 'b', 'c', 'd', 'd', '3', '5', '3', '0', '8', 'c', '9', '4', '8', '5', '5', '4', '8', '4', 'a', '4', 'c', '0', '1', '0', '0', '2', '7', 'f', 'e', '0', '4', 'f', '5']\n",
            "output_hat = ['4', 'c', '4', '4', 'c', 'c', '4', '4', 'c', '8', '4', 'c', 'c', 'c', 'c', 'c', '8', '8', '4', 'c', '4', '8', 'c', 'c', '4', 'c', '4', '8', '4', '8']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', 'c', '9', '5', '7', '7', '0', '4', 'a', 'd', '5', 'd', '3', 'd', '3', '8', 'b', 'c', 'c', '2', 'f', '5', '5', '5', '0', '5', '3', 'f', '0', '4', 'd', 'd', '5', '5', '3', 'd', '2', '0', '1', '0', '0', '3', '6', 'c', '9', '0', '5', '0', '6']\n",
            "output_hat = ['c', '8', '4', 'c', 'c', 'c', '8', 'c', '4', '8', 'c', 'c', 'c', 'c', 'c', 'c', '8', '8', '4', 'c', 'c', '8', 'c', 'c', 'c', '4', 'c', 'c', '8', '8', '4', '8', 'c', 'c', 'c', 'c', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', 'c', 'b', '2', 'f', '5', '1', '2', '8', 'c', '8', '2', 'f', '2', 'e', 'c', 'e', '4', 'c', 'c', 'a', '4', '9', '5', '5', '2', '8', 'c', '9', '5', '7', '2', '8', '4', 'a', 'c', 'd', '4', '9', '2', 'c', '4', '9', '0', '5', '0', '0', '6', '1', 'd', '1', '0', '8', '7', '3']\n",
            "output_hat = ['4', 'c', '4', 'c', 'c', '8', 'c', 'c', 'c', 'c', '4', 'c', 'c', '8', 'c', '8', '4', '8', '4', 'c', '4', '8', '4', '8', 'c', 'c', 'c', '8', '4', 'c', 'c', 'c', 'c', 'c', '4', '8', '4', '8', '4', '8', 'c', '8', '4', '8']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', '4', 'f', '2', 'c', '5', '6', 'f', '0', '4', '8', '4', 'c', '2', 'c', '4', 'b', '2', 'c', '4', 'a', '5', '1', 'f', '0', 'c', '9', 'c', 'c', 'c', '9', '4', '9', 'c', 'd', '4', '8', 'c', 'd', '4', 'c', 'd', '5', 'd', '3', '3', '3', 'd', '6', '3', '7', '3', '4', '5', '0', 'f', '0', '4', 'c', '0', '3', '0', '0', 'a', '3', '5', 'a', '0', '9', 'b', 'e']\n",
            "output_hat = ['c', 'c', '4', '8', 'c', '8', 'c', 'c', '8', 'c', '4', '8', '4', '8', 'c', '4', '4', '8', 'c', 'c', '4', '8', 'c', 'c', '8', '8', '4', '8', '4', '8', '4', '8', '4', '8', '4', 'c', '4', '8', '4', '8', '4', '8', 'c', 'c', 'c', 'c', '8', '8', 'c', 'c', '8', '8', '8', 'c', 'c', 'c', '8', '8', '4', '4']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', 'c', '9', '2', '8', 'c', 'a', 'c', 'c', 'c', '9', '2', '9', 'd', '6', '5', '1', '4', '8', 'c', 'c', 'c', '9', 'c', 'd', '2', 'f', '2', 'e', '5', '1', 'c', '8', 'c', 'b', '5', '7', '4', '8', '4', 'a', '2', 'c', '4', 'a', '0', '5', '0', '0', '6', '9', '4', 'd', '0', '8', '9', '6']\n",
            "output_hat = ['c', '8', '4', 'c', 'c', 'c', '4', '8', '4', '8', '4', '8', 'c', '8', 'c', '8', 'c', 'c', '4', '8', '4', '8', '4', '8', '4', 'c', 'c', '8', 'c', '8', 'c', 'c', '4', 'c', '4', 'c', 'c', 'c', '4', 'c', '4', '8', 'c', 'c', '4', '8']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', 'c', '9', '4', '8', '5', '5', '4', '8', '4', 'e', '2', 'c', '2', 'e', '5', '1', 'c', '8', '4', '8', '4', 'c', '5', '1', '4', '8', '4', 'a', '4', 'd', 'c', 'd', '0', '3', '0', '0', '3', '6', 'e', 'a', '0', '6', '1', '4']\n",
            "output_hat = ['c', '8', '4', 'c', '4', '8', 'c', 'c', '4', '8', '4', '8', 'c', '8', 'c', '8', 'c', 'c', '4', 'c', '4', '8', '4', '8', 'c', 'c', '4', 'c', '4', '8', '4', '8', '4', 'c']\n",
            "output = ['7', '8', '9', 'c', '4', 'b', '2', 'b', 'c', 'a', 'c', 'f', '5', '5', '4', '8', '5', '4', '2', '8', '4', '9', 'c', 'd', '4', '9', '2', 'd', '0', '0', '3', '2', '0', 'b', '4', 'a', '5', '2', '8', 'b', '1', '4', '3', '2', 'f', '2', 'c', 'b', '0', '1', '6', '8', 'd', '4', '0', '8', 'e', '7']\n",
            "output_hat = ['4', '4', 'c', 'c', '4', 'c', '4', '8', 'c', 'c', '4', '8', 'c', 'c', 'c', '8', '4', '8', '4', '8', '4', '8', 'c', 'c', 'c', 'c', '4', 'c', '4', '8', 'c', 'c', 'c', '8', '4', '8', 'c', 'c', 'c', 'c', '4', 'c', '4', 'c', 'c', 'c']\n",
            "output = ['7', '8', '9', 'c', '4', 'b', '4', 'c', '2', 'e', 'c', '9', 'c', 'c', 'c', 'f', '5', '3', '4', '8', '4', 'c', '2', '9', '4', 'b', 'c', 'd', '2', 'b', '2', '9', '2', 'd', '4', 'a', '5', '5', '2', '8', '2', 'e', 'a', '8', '5', '4', '4', '8', 'c', 'b', 'c', 'c', 'c', '9', '2', 'd', '0', '6', '0', '0', '8', '8', 'd', '6', '0', 'a', '2', '4']\n",
            "output_hat = ['4', '8', '4', '8', 'c', '8', '4', '8', '4', 'c', '4', 'c', 'c', 'c', '4', '8', '4', '8', 'c', '4', '4', '8', '4', 'c', 'c', '8', 'c', '8', 'c', 'c', '4', '8', 'c', 'c', 'c', '8', 'c', 'c', 'c', '8', 'c', 'c', '4', '4', '4', '8', '4', '8', '4', '8', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', '4', 'e', '2', 'd', 'c', 'a', '4', 'c', '2', 'd', '5', '6', 'c', '8', '2', 'c', '5', '6', 'c', '8', 'c', '8', '2', 'f', '5', '7', 'c', '8', '4', 'd', 'c', 'c', 'a', 'b', '0', '4', '0', '0', '4', '1', '0', '1', '0', '6', 'c', 'b']\n",
            "output_hat = ['c', '8', '4', '8', 'c', 'c', '4', '8', '4', '8', 'c', '8', 'c', 'c', '4', '8', 'c', '8', 'c', 'c', '4', 'c', '4', 'c', 'c', 'c', 'c', 'c', '4', '8', '4', '8', '4', 'c', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', '5', '3', '0', 'a', 'c', '9', '4', '8', '2', 'd', '4', 'a', '5', '5', '2', 'f', '5', '6', '2', '8', 'c', 'e', 'c', 'f', '4', 'd', '2', 'd', 'c', '9', 'c', '8', 'c', 'c', '4', 'b', '5', '7', '4', '8', '4', 'c', 'c', 'a', '2', 'f', '2', 'd', '5', '1', 'f', '0', '4', 'd', '2', 'c', 'a', 'a', '5', '4', '0', '2', '0', '0', 'a', '5', '2', '2', '0', 'a', 'b', '9']\n",
            "output_hat = ['c', 'c', '8', '8', '4', 'c', '4', '8', 'c', 'c', '4', '8', 'c', 'c', 'c', '8', 'c', 'c', 'c', '8', '4', 'c', '4', '8', '4', '8', 'c', '8', '4', 'c', '4', '8', '4', 'c', '4', 'c', 'c', 'c', '4', '8', '4', 'c', '4', 'c', 'c', '8', 'c', '8', 'c', 'c', '8', '8', '4', '8', 'c', 'c', 'c', '8', 'c', 'c']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', 'c', 'd', '4', 'b', '4', 'a', 'c', 'c', '4', '9', 'c', 'c', '4', 'b', '4', 'e', '4', 'd', 'd', '1', '5', '3', 'f', '0', '5', '4', '4', '8', '4', '9', '2', 'c', '4', 'a', '5', '5', '4', '8', 'c', 'c', 'a', 'b', '0', '4', '0', '0', '5', 'c', '3', 'b', '0', '7', 'c', '9']\n",
            "output_hat = ['c', '8', '4', 'c', '4', 'c', '4', '8', '4', '8', '4', '8', '4', 'c', '4', '8', '4', '8', '4', '8', 'c', 'c', 'c', 'c', '8', '8', 'c', 'c', '4', '8', '4', '8', 'c', 'c', '4', '8', 'c', 'c', '4', '8', '4', 'c', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', '4', 'f', '5', '3', '2', '8', 'c', 'f', '4', '8', '2', 'c', '5', '1', 'c', '8', '4', '8', '5', '5', '4', '8', 'c', '9', '4', 'c', 'd', '1', '0', '1', '0', '0', '2', 'a', '4', '3', '0', '5', '1', '4']\n",
            "output_hat = ['4', 'c', '4', '4', 'c', 'c', 'c', 'c', '4', 'c', '4', '8', 'c', '8', 'c', 'c', '4', 'c', '4', '8', 'c', 'c', '4', '8', '4', '8', '4', '8', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', '0', 'b', 'c', 'f', '2', 'c', 'c', '9', '5', '0', '2', '8', 'c', '9', '4', '8', '5', '5', '4', '8', '4', 'c', '2', '9', '4', 'b', 'c', 'd', '2', 'b', '5', '1', 'c', '8', '4', 'f', '0', '3', '0', '0', '3', 'e', '5', '7', '0', '6', '9', '5']\n",
            "output_hat = ['8', 'c', '4', '8', 'c', '8', '4', 'c', 'c', 'c', 'c', '8', '4', 'c', '4', '8', 'c', 'c', '4', '8', '4', '8', 'c', '4', '4', '8', '4', 'c', 'c', '8', 'c', 'c', '4', 'c', '4', '4']\n",
            "output = ['7', '8', '9', 'c', '4', 'b', 'c', 'c', 'a', 'b', 'c', 'c', 'c', 'f', '4', 'b', '5', '5', '2', '8', 'c', '9', '4', '8', '2', 'c', '5', '1', 'c', '8', 'c', 'd', '4', 'c', 'c', 'f', '2', '8', '0', '1', '3', '2', '3', '3', 'f', '3', 'b', '2', '0', '1', '6', 'a', '4', '3', '0', '8', 'd', '3']\n",
            "output_hat = ['4', '8', '4', 'c', 'c', '8', '4', 'c', '4', 'c', '4', '8', 'c', 'c', 'c', '8', '4', 'c', '4', '8', 'c', '8', 'c', 'c', '4', '8', '4', '8', '4', 'c', '4', 'c', 'c', '8', 'c', 'c', 'c', '8', '4', 'c', '4', '8', '4', 'c', '4', '8']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', 'c', 'd', '2', 'f', 'c', 'b', '4', 'c', '5', '5', 'c', '8', '2', 'c', '5', '6', 'c', '8', 'c', 'd', '2', 'f', '4', 'a', '5', '5', '4', '8', 'c', 'b', '2', 'f', '0', '2', '0', '0', '3', '9', 'c', '0', '0', '6', '5', '7']\n",
            "output_hat = ['4', '8', '4', 'c', 'c', '4', '4', '8', '4', '8', 'c', 'c', '4', '8', 'c', '8', 'c', 'c', '4', '8', '4', 'c', 'c', 'c', '4', '8', 'c', 'c', '4', '4', '4', 'c', 'c', 'c']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', '4', '8', '2', 'c', '2', 'a', '5', '1', '4', '8', '4', 'a', '2', 'd', '2', '9', '4', '9', '2', 'd', 'd', '2', '5', '3', '7', '0', 'c', 'c', '4', 'b', '5', '1', 'c', '8', '2', 'c', '0', '1', '0', '0', '4', '5', 'f', '6', '0', '6', 'b', 'c']\n",
            "output_hat = ['c', 'c', '4', '8', 'c', 'c', 'c', '8', 'c', 'c', '4', 'c', '4', '8', 'c', '8', 'c', '8', '4', '8', 'c', 'c', 'c', 'c', 'c', 'c', '8', '8', '4', 'c', '4', '8', 'c', 'c', '4', '8', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', 'c', 'f', '4', 'b', '5', '5', 'c', '8', '4', 'f', '5', '3', 'c', '8', 'c', '8', '2', 'c', '5', '6', 'c', '8', 'c', 'd', '2', 'f', '2', 'e', '0', '1', '0', '0', '2', 'a', 'e', '2', '0', '5', '7', 'f']\n",
            "output_hat = ['4', 'c', '4', 'c', '4', '8', 'c', 'c', '4', 'c', '4', '4', 'c', 'c', '4', 'c', '4', '8', 'c', '8', 'c', 'c', '4', '8', '4', 'c', 'c', '8', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', '4', '9', '2', 'd', '2', 'a', 'c', 'a', '4', 'c', 'a', 'b', 'c', 'c', 'c', 'c', '4', 'b', '5', '7', '4', '8', '2', 'c', 'c', '9', 'c', 'd', '2', 'f', '2', 'e', 'c', '8', '4', '8', '2', 'd', '4', 'a', 'd', '5', '5', '3', '7', '0', '2', 'c', '5', '6', '2', '8', '4', 'f', 'c', 'd', 'c', '9', '0', '1', '0', '0', 'b', '8', 'b', 'a', '0', 'b', '7', '2']\n",
            "output_hat = ['c', '8', '4', '8', 'c', 'c', 'c', 'c', '4', '8', '4', '4', 'c', '8', '4', '8', '4', 'c', '4', 'c', 'c', 'c', '4', '8', 'c', '8', '4', '8', '4', 'c', 'c', '8', 'c', 'c', '4', 'c', '4', '8', 'c', 'c', '4', '8', 'c', 'c', 'c', 'c', '8', '8', 'c', '8', 'c', 'c', 'c', 'c', '4', '8', '4', '8', '4', '8']\n",
            "output = ['7', '8', '9', 'c', '7', '3', '2', 'a', 'c', 'a', '2', 'f', 'c', '9', '4', '8', '2', 'd', '2', 'a', 'd', '6', '5', '1', '4', '8', 'c', 'c', '4', 'b', '5', '1', '4', '8', 'c', '9', '2', 'c', '4', 'a', '4', 'd', '2', 'e', 'c', '9', '2', 'f', '5', '2', '0', '8', '4', 'a', 'c', 'c', '2', 'f', 'c', 'd', '0', '1', '0', '0', '9', '5', '9', '7', '0', 'a', '6', '8']\n",
            "output_hat = ['8', 'c', 'c', 'c', '4', 'c', 'c', '8', '4', 'c', '4', '8', 'c', 'c', 'c', '8', 'c', '8', 'c', 'c', '4', '8', '4', 'c', '4', '8', 'c', 'c', '4', '8', '4', '8', 'c', 'c', '4', '8', '4', '8', 'c', '8', '4', 'c', 'c', 'c', 'c', 'c', '8', 'c', '4', '8', '4', 'c', 'c', '8', '4', '8']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', 'c', '8', 'c', '9', '2', 'f', '5', '1', 'c', '8', 'c', '8', 'c', 'f', '4', '9', '2', 'd', 'd', '6', '5', '1', 'c', '8', '4', 'f', '5', '3', '4', '8', 'c', 'e', '2', 'f', '2', 'd', '2', 'a', '4', 'e', '0', '5', '0', '0', '5', '5', 'b', '5', '0', '7', 'c', 'd']\n",
            "output_hat = ['c', 'c', '4', '8', '4', 'c', 'c', '8', 'c', 'c', '4', 'c', '4', 'c', '4', '8', '4', '8', 'c', '8', 'c', '8', 'c', 'c', '4', 'c', '4', '4', 'c', 'c', '4', '8', '4', 'c', 'c', '8', 'c', 'c', 'c', '8', '4', '8']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', '2', 'f', '5', '2', '4', '8', '5', '4', '2', '8', '4', 'b', '2', 'd', 'a', 'a', '5', '4', '2', '8', '2', 'e', '4', '8', '4', 'd', 'c', 'e', '4', 'c', 'c', 'c', '0', '1', '0', '0', '3', '6', 'a', '5', '0', '6', '4', 'a']\n",
            "output_hat = ['4', 'c', 'c', 'c', 'c', 'c', '4', '8', 'c', 'c', 'c', '4', '4', '8', 'c', 'c', 'c', '8', 'c', 'c', 'c', '8', 'c', 'c', '4', '8', '4', '8', '4', '8', '4', '8', '4', '8']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', 'c', 'd', '2', 'f', 'c', 'b', '4', 'c', '5', '5', 'f', '0', '5', '4', '2', 'f', '4', 'b', '5', '5', '4', '8', 'c', 'd', 'c', 'b', 'c', 'a', 'a', 'f', '4', 'c', '4', 'd', '5', '1', '2', '8', '4', 'e', '2', 'd', '4', 'b', '2', 'd', '4', 'a', 'c', 'c', '0', '1', '0', '0', '7', 'f', '8', '1', '0', '9', 'a', 'c']\n",
            "output_hat = ['4', '8', '4', 'c', 'c', '4', '4', '8', '4', '8', 'c', 'c', '8', '8', 'c', 'c', 'c', '4', '4', '8', 'c', 'c', '4', '8', '4', 'c', '4', '8', '4', 'c', 'c', '8', '4', '8', '4', '8', 'c', 'c', 'c', '8', '4', '8', 'c', '4', '4', '8', 'c', 'c', '4', '8', '4', '8']\n",
            "output = ['7', '8', '9', 'c', 'a', 'b', 'c', 'c', '2', 'f', '5', '5', '4', '8', '2', 'c', '4', 'a', '5', '5', '2', '8', '4', 'a', 'c', 'd', 'c', '9', '4', 'c', '2', 'd', '4', 'b', '4', 'd', '5', '1', 'c', '8', 'c', 'f', '0', '3', '0', '0', '4', '7', 'd', '5', '0', '7', '2', '3']\n",
            "output_hat = ['c', '8', '4', 'c', 'c', '8', 'c', 'c', '4', '8', 'c', 'c', '4', '8', 'c', 'c', 'c', 'c', '4', '8', '4', '8', '4', '8', '4', '8', 'c', '4', '4', '8', '4', '8', 'c', 'c', '4', 'c', '4', 'c']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', 'c', '9', '2', 'f', '4', 'f', '2', 'c', '4', 'a', '2', '9', '5', '6', '2', '8', 'c', '9', '4', '8', '5', '5', '4', '8', 'c', 'd', '4', 'b', '5', '1', 'c', '8', '4', 'f', '0', '3', '0', '0', '4', '2', 'b', 'c', '0', '6', 'b', '2']\n",
            "output_hat = ['c', '8', '4', 'c', 'c', 'c', '4', '8', 'c', 'c', '4', '8', 'c', '8', 'c', 'c', 'c', '8', '4', 'c', '4', '8', 'c', 'c', '4', '8', '4', 'c', '4', '8', 'c', 'c', '4', 'c', '4', '4']\n",
            "output = ['7', '8', '9', 'c', 'f', '3', '2', 'c', '5', '1', '2', '8', '4', 'f', '2', 'c', '5', '6', '2', '8', 'c', 'e', '5', '7', '2', '8', '4', '9', 'c', 'c', '4', 'd', 'd', '5', '0', '1', '0', '0', '2', '9', '1', '1', '0', '5', '1', 'e']\n",
            "output_hat = ['8', '8', 'c', '8', 'c', 'c', 'c', 'c', '4', '8', 'c', '8', 'c', 'c', 'c', '8', '4', 'c', 'c', 'c', 'c', '8', '4', '8', '4', '8', '4', '8', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', 'c', 'b', '2', 'f', '5', '1', '4', '8', '2', 'f', '4', 'a', '4', 'd', '2', 'c', '5', '1', '0', '0', 'a', '1', '9', 'c', '1', 'c', '3', 'd', '0', '0', '3', '8', '7', '0', '0', '6', '0', '1']\n",
            "output_hat = ['4', 'c', '4', 'c', 'c', '8', 'c', 'c', '4', 'c', 'c', 'c', '4', '8', '4', '8', 'c', '8', 'c', 'c', '4', '8', 'c', '8', 'c', 'c', '4', '8', '4', '8', '4', '8', 'c', 'c']\n",
            "output = ['7', '8', '9', 'c', 'c', 'b', 'c', 'f', '5', '3', '4', '8', 'c', 'c', '5', '3', 'c', '8', 'c', 'f', '2', 'b', 'c', 'e', '4', '9', '2', 'c', '4', 'd', 'c', 'f', '2', '8', '5', '1', 'c', '8', '4', 'f', '0', '3', '0', '0', '3', 'e', 'd', 'a', '0', '6', 'b', '7']\n",
            "output_hat = ['4', 'c', '4', 'c', 'c', 'c', '4', '8', '4', 'c', 'c', 'c', '4', 'c', '4', 'c', 'c', '8', '4', '8', '4', '8', 'c', '8', '4', 'c', '4', 'c', 'c', '8', 'c', 'c', '4', 'c', '4', '4']\n",
            "output = ['7', '8', '9', 'c', '2', 'b', 'c', 'a', '4', 'c', 'c', 'f', '2', '8', 'b', '1', '5', '7', 'f', '0', 'c', 'b', '4', 'f', 'c', 'a', '4', 'f', 'a', '9', '5', '4', '2', '8', 'c', 'f', '2', 'f', 'c', 'd', '4', '9', '5', '1', '4', '8', '4', 'c', '2', 'e', '2', '9', '4', 'd', 'c', 'c', 'c', '9', 'a', '9', '0', '4', '0', '0', '9', '7', 'e', 'c', '0', 'a', 'b', '3']\n",
            "output_hat = ['c', 'c', '4', '8', '4', 'c', '4', 'c', 'c', '8', '8', 'c', 'c', 'c', '8', 'c', '4', 'c', '4', 'c', '4', 'c', '4', '8', 'c', '8', 'c', 'c', 'c', 'c', '4', 'c', 'c', '8', '4', '8', '4', '8', 'c', 'c', '4', '8', '4', '8', 'c', '8', 'c', '8', '4', '8', '4', '8', '4', '8', 'c', '8']\n",
            "output = ['7', '8', '9', 'c', '7', '3', 'c', 'b', '2', 'c', '2', 'a', '2', 'e', 'd', '1', '5', '1', '2', '8', 'c', 'e', '4', '8', '5', '5', 'c', '8', '2', 'c', '5', '6', '2', '8', '4', 'f', 'a', 'c', '0', '4', '0', '0', '3', '5', '9', '6', '0', '6', '0', '2']\n",
            "output_hat = ['8', '4', '4', '8', 'c', 'c', 'c', '8', 'c', '8', 'c', '8', 'c', 'c', 'c', '8', '4', 'c', '4', '8', 'c', 'c', '4', '8', 'c', '8', 'c', 'c', 'c', 'c', '4', '8', 'c', '8']\n",
            "(41.4375, [])\n"
          ]
        }
      ],
      "source": [
        "if SEQ2SEQ:\n",
        "    model = Seq2Seq(tokenizer, model)\n",
        "    trainer = pl.Trainer(\n",
        "        precision='16-mixed',\n",
        "        max_epochs=MAX_EPOCHS,\n",
        "        enable_progress_bar=True,\n",
        "        callbacks=[EarlyStopping(monitor='val_loss', patience=3)]\n",
        "    )\n",
        "    trainer.fit(model, train_dataloader, val_dataloader)\n",
        "    trainer.test(model, test_dataloader)\n",
        "elif RNN:\n",
        "    model = Recurrent()\n",
        "    trainer = pl.Trainer(max_epochs=MAX_EPOCHS)\n",
        "    trainer.fit(model, train_dataloader, val_dataloader)\n",
        "    print(evaluate(_device = \"cpu\", _print = True, _training= False))\n",
        "else:\n",
        "  model = FeedForward()\n",
        "  trainer = pl.Trainer(max_epochs=MAX_EPOCHS)\n",
        "  trainer.fit(model, train_dataloader, val_dataloader)\n",
        "  print(evaluate(_device = \"cpu\", _print = True, _training= False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As last approach we decided to experiment with the cutting edge in the NLP field: Large Language Models. As\n",
        "mentioned previously in our discussion on Seq2Seq models, we opted for LLMs due to their significant power, although\n",
        "we were aware that this task might not diverge greatly from their training experiences. Therefore we did not anticipate\n",
        "superior performance compared to earlier models.\n",
        "\n",
        "\n",
        "LLM training is computationally expensive due to their high number of parameters and impossible to train on Colab.\n",
        "That’s why we used LoRa, which allowed us not to train all parameters of the model but just two smaller matrices that\n",
        "only after the training phase are merged with the original LLM. Again due to colab restrictions reasons we couldn’t\n",
        "load a huge model, thus we decided to use a relatively small LLM called facebook/opt-350m. This model has 350\n",
        "millions parameters, but thanks to PEFT (that supports QLoRa natively) and BitsAndBytes we loaded this model in 4bit\n",
        "quantization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if SHORT:\n",
        "  df = pd.read_csv('/content/mediumhex2hex.csv')\n",
        "elif RANDOMIZED_SHORT:\n",
        "  df = pd.read_csv('/content/randomized_shorthex2hex.csv')\n",
        "elif MEDIUM:\n",
        "  df = pd.read_csv('/content/shorthex2hex.csv')\n",
        "\n",
        "\n",
        "df = df[:40960]\n",
        "\n",
        "ds = Dataset.from_pandas(df)\n",
        "ds = ds.remove_columns(\"text\")\n",
        "ds_train_test = ds.train_test_split(test_size=0.2, seed=SEED)\n",
        "ds_test_dev = ds_train_test['test'].train_test_split(test_size=0.5, seed=SEED)\n",
        "ds_splits = DatasetDict({\n",
        "    'train': ds_train_test['train'],\n",
        "    'valid': ds_test_dev['train'],\n",
        "    'test': ds_test_dev['test']\n",
        "})\n",
        "\n",
        "ds_splits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model from HF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"facebook/opt-350m\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_compute_dtype=\"float16\",\n",
        "        bnb_4bit_use_double_quant=False,\n",
        "    )\n",
        ")\n",
        "model.config.use_cache = False\n",
        "model.config.pretraining_tp = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"right\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add LoRA adapters to model\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\",\"v_proj\",\"o_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "lora_model = get_peft_model(model, config)\n",
        "lora_model.config.use_cache = False\n",
        "print_trainable_parameters(lora_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size=8  # batch size\n",
        "gradient_accumulation_steps=1  # gradient acc. steps\n",
        "num_train_epochs=3\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./output/\",\n",
        "    #report_to=\"wandb\",  # this tells the Trainer to log the metrics to W&B\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size//2,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    learning_rate=2e-4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio = 0.1,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    gradient_checkpointing=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    # logging strategies\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=1,\n",
        "    save_strategy=\"epoch\", # saving is done at the end of each epoch\n",
        ")\n",
        "\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    args=training_args,\n",
        "    model=model,\n",
        "    peft_config = config,\n",
        "    train_dataset=ds_splits['train'],\n",
        "    eval_dataset=ds_splits['valid'],\n",
        "    formatting_func=formatting_func_with_response,\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_length=300,\n",
        "    packing=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input = \"5468697320697320616d617a696e672d6c6f6f6b696e67206d6f766965\"\n",
        "target = \"789c0bc9c82c5600a2c4dcc4aaccbc74dd9cfcfc6c20ad909b5f96990a00a1320afc\"\n",
        "\n",
        "batch = tokenizer(f\"Give me your best shot. Encode this in the way you learned: {input}\\n ###Answer:\", return_tensors='pt').to(\"cuda\")\n",
        "\n",
        "with torch.cuda.amp.autocast():\n",
        "  output = model.generate(\n",
        "      **batch,\n",
        "      max_new_tokens=100,\n",
        "      top_p=1.0,\n",
        "      top_k=30,\n",
        "      temperature=1.0,\n",
        "      do_sample=True,\n",
        ")\n",
        "\n",
        "for seq in output:\n",
        "  print(tokenizer.decode(seq, skip_special_tokens=True), \"\\n\")\n",
        "\n",
        "print(f\"###Target:{target}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4503096,
          "sourceId": 7711642,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4592427,
          "sourceId": 7834971,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30665,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "021dfb1e492448e1b4a817f573493805": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d013ebb2b0c040c9b48e3ea69a970f78",
            "placeholder": "​",
            "style": "IPY_MODEL_a8912df1b80a47b3b23e11bc0d09016e",
            "value": "Epoch 0: 100%"
          }
        },
        "0447e03163294685a7c68bb092bb3f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "076d745cfeb74e1b91650d911bcbf61f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7aadecf205f04732bcd4c9c48ac9c2c6",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0447e03163294685a7c68bb092bb3f39",
            "value": 32
          }
        },
        "0de15e901b9e447c935d03f3abbb7181": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e66adf27f81e45af8f99afb63355fcee",
            "placeholder": "​",
            "style": "IPY_MODEL_5ddf57a4a7d24902b5f852453231a5c3",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "0f6ad78f8a64499ba618004a60df6697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60c7f11ac08846f99d73a916496cb92c",
              "IPY_MODEL_7883a2398945478eaaeb96d56ee38b84",
              "IPY_MODEL_5933849bbd3c428c81082dbce63d18ff"
            ],
            "layout": "IPY_MODEL_aec78a401d0f40d599bc72d34ed6f7e8"
          }
        },
        "20d38a1bc02c4c7aa7d82bca56bfda83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6373de30df414018966cdf60f27489b7",
            "max": 256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca1602a0c3844f22aabb9e0a9ef27c37",
            "value": 256
          }
        },
        "36b51407c0f141da91e895e142921b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a0a6fc2c1c64e32a9d38816703bf8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fead76e6089246a4acfe2353492ffb50",
            "placeholder": "​",
            "style": "IPY_MODEL_9197deb1965648d6a6f250e0b3161ef9",
            "value": " 32/32 [00:00&lt;00:00, 52.14it/s]"
          }
        },
        "56bf8723fc664d098c9f2c487a75ec13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_021dfb1e492448e1b4a817f573493805",
              "IPY_MODEL_20d38a1bc02c4c7aa7d82bca56bfda83",
              "IPY_MODEL_df09131b522745ccb8b0656989d9f2a8"
            ],
            "layout": "IPY_MODEL_b84e86cc8b1a4b81995a04bcf2cdb1ad"
          }
        },
        "5933849bbd3c428c81082dbce63d18ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62ec2038927d4499bb7aac028ba397d5",
            "placeholder": "​",
            "style": "IPY_MODEL_36b51407c0f141da91e895e142921b6d",
            "value": " 2/2 [00:01&lt;00:00,  1.51it/s]"
          }
        },
        "5af6274fdeb7460dba6b5fb21ed9dda1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ddf57a4a7d24902b5f852453231a5c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60c7f11ac08846f99d73a916496cb92c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd34f80f92bf4c759a994a45ad9d0574",
            "placeholder": "​",
            "style": "IPY_MODEL_d6caea833dab45669f8eefb5f8335e22",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "61bedbd86957498895a0e2bf2f7681e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "62ec2038927d4499bb7aac028ba397d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6373de30df414018966cdf60f27489b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7883a2398945478eaaeb96d56ee38b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88ae069397e64ef8955d657581ccfff3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5af6274fdeb7460dba6b5fb21ed9dda1",
            "value": 2
          }
        },
        "7aadecf205f04732bcd4c9c48ac9c2c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88ae069397e64ef8955d657581ccfff3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "894026c6b2da4a39955527d5aeb5e85f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8fd0e718d24812a67d356c6006fe71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0de15e901b9e447c935d03f3abbb7181",
              "IPY_MODEL_076d745cfeb74e1b91650d911bcbf61f",
              "IPY_MODEL_4a0a6fc2c1c64e32a9d38816703bf8ae"
            ],
            "layout": "IPY_MODEL_61bedbd86957498895a0e2bf2f7681e6"
          }
        },
        "9197deb1965648d6a6f250e0b3161ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8912df1b80a47b3b23e11bc0d09016e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aec78a401d0f40d599bc72d34ed6f7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "b84e86cc8b1a4b81995a04bcf2cdb1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c170728a5c984cca85b0a5d42e4a2559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca1602a0c3844f22aabb9e0a9ef27c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd34f80f92bf4c759a994a45ad9d0574": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d013ebb2b0c040c9b48e3ea69a970f78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6caea833dab45669f8eefb5f8335e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df09131b522745ccb8b0656989d9f2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894026c6b2da4a39955527d5aeb5e85f",
            "placeholder": "​",
            "style": "IPY_MODEL_c170728a5c984cca85b0a5d42e4a2559",
            "value": " 256/256 [00:10&lt;00:00, 24.80it/s, v_num=1, train_loss=0.747, val_loss=0.753]"
          }
        },
        "e66adf27f81e45af8f99afb63355fcee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fead76e6089246a4acfe2353492ffb50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
