{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7596476,"sourceType":"datasetVersion","datasetId":4290346}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install lightning datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-13T18:03:17.424136Z","iopub.execute_input":"2024-02-13T18:03:17.424966Z","iopub.status.idle":"2024-02-13T18:03:34.032650Z","shell.execute_reply.started":"2024-02-13T18:03:17.424932Z","shell.execute_reply":"2024-02-13T18:03:34.031330Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom datasets import load_dataset, Dataset, DatasetDict\nfrom torch.utils.data import DataLoader\nfrom typing import Dict, List, Tuple\nfrom dataclasses import dataclass\nfrom pprint import pprint\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport lightning as L\nimport random\n\nSEED = 999\nBATCH_SIZE = 32\ntorch.manual_seed(SEED)\nL.seed_everything(SEED)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:34.034548Z","iopub.execute_input":"2024-02-13T18:03:34.034869Z","iopub.status.idle":"2024-02-13T18:03:42.725841Z","shell.execute_reply.started":"2024-02-13T18:03:34.034841Z","shell.execute_reply":"2024-02-13T18:03:42.724833Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"INFO: Seed set to 999\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"999"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:42.727194Z","iopub.execute_input":"2024-02-13T18:03:42.727867Z","iopub.status.idle":"2024-02-13T18:03:42.757030Z","shell.execute_reply.started":"2024-02-13T18:03:42.727828Z","shell.execute_reply":"2024-02-13T18:03:42.755902Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/hexadecimalzip/randomized_shorthex2hex.csv')\ndf = df[:12000]\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:42.760645Z","iopub.execute_input":"2024-02-13T18:03:42.761037Z","iopub.status.idle":"2024-02-13T18:03:43.118914Z","shell.execute_reply.started":"2024-02-13T18:03:42.761002Z","shell.execute_reply":"2024-02-13T18:03:43.117725Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"                      text                                        text_hex  \\\n0            this is not a                      74686973206973206e6f742061   \n1  and gives a comforting,  616e64206769766573206120636f6d666f7274696e672c   \n2  killer). While some may  6b696c6c6572292e205768696c6520736f6d65206d6179   \n3          in his closet &                  696e2068697320636c6f7365742026   \n4       film to watch. Mr.            66696c6d20746f2077617463682e204d722e   \n\n                                         deflate_hex  \n0             789c2bc9c82c5600a2bcfc1285440021fe04a7  \n1  789c4bcc4b5148cf2c4b2d56485448cecf4dcb2f2ac9cc...  \n2  789ccbceccc9492dd2d45308cfc8cc495528cecf4d55c8...  \n3     789ccbcc53c8c82c5648cec92f4e2d515003002b16052c  \n4  789c4bcbccc95528c957284f2c49ced053f02dd203003d...  \n","output_type":"stream"}]},{"cell_type":"code","source":"df['text_hex'] = 'S' + df['text_hex'] + 'E'\ndf['deflate_hex'] = 'S' + df['deflate_hex'] + 'E'","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:43.120440Z","iopub.execute_input":"2024-02-13T18:03:43.120735Z","iopub.status.idle":"2024-02-13T18:03:43.135134Z","shell.execute_reply.started":"2024-02-13T18:03:43.120711Z","shell.execute_reply":"2024-02-13T18:03:43.134041Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"ds = Dataset.from_pandas(df)\nds_train_test = ds.train_test_split(test_size=0.2, seed=SEED)\nds_test_dev = ds_train_test['test'].train_test_split(test_size=0.5, seed=SEED)\nds_splits = DatasetDict({\n    'train': ds_train_test['train'],\n    'valid': ds_test_dev['train'],\n    'test': ds_test_dev['test']\n})\n\nds_splits","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:43.136954Z","iopub.execute_input":"2024-02-13T18:03:43.137299Z","iopub.status.idle":"2024-02-13T18:03:43.219693Z","shell.execute_reply.started":"2024-02-13T18:03:43.137275Z","shell.execute_reply":"2024-02-13T18:03:43.218790Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'text_hex', 'deflate_hex'],\n        num_rows: 9600\n    })\n    valid: Dataset({\n        features: ['text', 'text_hex', 'deflate_hex'],\n        num_rows: 1200\n    })\n    test: Dataset({\n        features: ['text', 'text_hex', 'deflate_hex'],\n        num_rows: 1200\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"ds_splits['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:43.220856Z","iopub.execute_input":"2024-02-13T18:03:43.221131Z","iopub.status.idle":"2024-02-13T18:03:43.227379Z","shell.execute_reply.started":"2024-02-13T18:03:43.221107Z","shell.execute_reply":"2024-02-13T18:03:43.226468Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'text': 'The D is the',\n 'text_hex': 'S546865204420697320746865E',\n 'deflate_hex': 'S789c0bc948557051c82c5628c9480500184c03e3E'}"},"metadata":{}}]},{"cell_type":"code","source":"token2id = {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4, \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9, \"a\": 10, \"b\": 11, \"c\": 12, \"d\": 13, \"e\": 14, \"f\": 15, \"P\":16, \"S\": 17, \"E\":18 }\n\ndef create_id2token_vocab(token_to_id):\n    id2token = {}\n    for token, id in token_to_id.items():\n        id2token[id] = token\n\n    return id2token\n\nid2token = create_id2token_vocab(token2id)\nid2token","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:43.228789Z","iopub.execute_input":"2024-02-13T18:03:43.229053Z","iopub.status.idle":"2024-02-13T18:03:43.240209Z","shell.execute_reply.started":"2024-02-13T18:03:43.229031Z","shell.execute_reply":"2024-02-13T18:03:43.239328Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{0: '0',\n 1: '1',\n 2: '2',\n 3: '3',\n 4: '4',\n 5: '5',\n 6: '6',\n 7: '7',\n 8: '8',\n 9: '9',\n 10: 'a',\n 11: 'b',\n 12: 'c',\n 13: 'd',\n 14: 'e',\n 15: 'f',\n 16: 'P',\n 17: 'S',\n 18: 'E'}"},"metadata":{}}]},{"cell_type":"code","source":"def collate_fn(batch):\n\n  def pad_sequences(sequences, maxlen, value=token2id['P']):\n    padded_sequences = []\n    for sequence in sequences:\n        padded_sequence = sequence[:maxlen]\n        padded_sequence.extend([value] * (maxlen - len(padded_sequence)))\n\n        padded_sequence = sequence +  [value] * (maxlen - len(sequence))\n        padded_sequences.append(padded_sequence)\n\n    return padded_sequences\n\n\n  texts = [elem['text_hex'] for elem in batch]\n  encoded_hex = [[token2id[x] for x in hex] for hex in texts]\n\n\n  outputs = [elem['deflate_hex'] for elem in batch]\n  encoded_outputs = [[token2id[x] for x in hex] for hex in outputs]\n\n\n  maxlen = 0\n  for seq in encoded_hex:\n    if len(seq) > maxlen:\n      maxlen = len(seq)\n  for seq in encoded_outputs:\n    if len(seq) > maxlen:\n      maxlen = len(seq)\n\n  padded_encoded_hex = pad_sequences(encoded_hex, maxlen)\n  padded_encoded_outputs = pad_sequences(encoded_outputs, maxlen)\n\n\n  return {\n      'inputs': torch.tensor(padded_encoded_hex),\n      \"outputs\": torch.tensor(padded_encoded_outputs)\n  }\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:43.241319Z","iopub.execute_input":"2024-02-13T18:03:43.241641Z","iopub.status.idle":"2024-02-13T18:03:43.251336Z","shell.execute_reply.started":"2024-02-13T18:03:43.241607Z","shell.execute_reply":"2024-02-13T18:03:43.250417Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import nltk\nfrom nltk.metrics.distance import edit_distance\n\ndef decode_output(output):\n    return ''.join([id2token[int(id)] for id in output])\n\ndef decode_input(input):\n    return ''.join([id2token[int(id)] for id in input])\n\ndef evaluate(batch, _device, _print, _cycle, _training):\n    model.eval()\n    total_distance = 0\n    total = 0\n    \n    distances_list = []\n    \n    #print(f\"Batch inputs shape = {batch['inputs'].shape}\")\n    #print(f\"Batch outputs shape = {batch['outputs'].shape}\")\n\n    x = batch[\"inputs\"].transpose(0,1).to(_device)\n    y = batch[\"outputs\"].transpose(0,1).to(_device)\n\n    y_hat = model(x, y)\n    y_hat = torch.argmax(y_hat, dim=-1)\n    \n    y = y.transpose(0,1)\n    y_hat = y_hat.transpose(0,1)\n    \n    assert len(y) == len(y_hat)\n    \n    for i in range(len(y)):\n        output = decode_output(y[i])\n        output_hat = decode_output(y_hat[i])\n\n        output = [x for x in output if x != \"P\"]\n        output_hat = [x for x in output_hat if x != \"P\"]\n\n        first_eos_index = 0\n        for i in range(len(output_hat)):\n            if output_hat[i] == \"E\":\n                first_eos_index = i\n                break\n\n        # REMOVE START OF SEQUENCE TOKEN\n        output = output[1:]\n        output_hat = output_hat[1:first_eos_index]\n        distance = edit_distance(output, output_hat)\n        distances_list.append(distance)\n\n        if _print:\n            print(f\"output = {output}\")\n            print(f\"output_hat = {output_hat}\")\n\n        total_distance += distance\n        total += 1\n\n        if distance == 0:\n            print(f\"DISTANCE = 0!\")\n            print(f\"output = {output}\")\n            print(f\"output_hat = {output_hat}\")\n            \n    if _training:\n        return total_distance/total\n    \n    return (total_distance/total, distances_list)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:03:43.254342Z","iopub.execute_input":"2024-02-13T18:03:43.254725Z","iopub.status.idle":"2024-02-13T18:03:44.435995Z","shell.execute_reply.started":"2024-02-13T18:03:43.254702Z","shell.execute_reply":"2024-02-13T18:03:44.435113Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import pytorch_lightning as pl\nimport torch\nimport torch.nn as nn\nimport random\n\ntorch.set_printoptions(profile=\"full\")\n\nEPOCHS = 100\nLR = 3e-4\nEMBEDDING_DIM = 256\nHIDDEN_DIM = 512\nNUM_LAYERS = 4\nDROPOUT = 0.4\nBIDIRECTIONAL = False\nMAX_SEQ_LEN = 256\nBATCH_SIZE = 1024\n\n# Global variable to choose the RNN type\nRNN_TYPE = 'RNN'  # Options: 'LSTM', 'GRU', 'RNN'\n\nclass Seq2Seq(pl.LightningModule):\n    def __init__(self, vocab_len, embedding_dim, hidden_dim, output_dim, num_layers, bidirectional, dropout):\n        super(Seq2Seq, self).__init__()\n        self.rnn_type = RNN_TYPE\n        self.embedding = nn.Embedding(vocab_len, embedding_dim, padding_idx=token2id['P'])\n        \n        if self.rnn_type == 'LSTM':\n            rnn_cell = nn.LSTM\n        elif self.rnn_type == 'GRU':\n            rnn_cell = nn.GRU\n        else:  # Default to RNN if neither LSTM nor GRU is selected\n            rnn_cell = nn.RNN\n        \n        self.encoder_rnn = rnn_cell(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout if num_layers > 1 else 0)\n        self.decoder_rnn = rnn_cell(embedding_dim, hidden_dim, num_layers=num_layers, bidirectional=bidirectional, dropout=dropout if num_layers > 1 else 0)\n        \n        self.dropout = nn.Dropout(dropout)\n        self.output_dim = output_dim\n        self.linear = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n        self.criterion = nn.CrossEntropyLoss()\n\n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        target_len = target.shape[0]\n        batch_size = target.shape[1]\n        target_vocab_size = self.output_dim\n\n        outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(self.device)\n\n        x = self.dropout(self.embedding(source))\n        rnn_output, h = self.encoder_rnn(x)\n\n        x = target[0]\n        for t in range(1, target_len):\n            x = self.dropout(self.embedding(x.unsqueeze(0)))\n            out, h = self.decoder_rnn(x, h if self.rnn_type in ['LSTM', 'GRU'] else None)\n            predictions = self.linear(out)\n            predictions = predictions.squeeze(0)\n            outputs[t] = predictions\n            pred = predictions.argmax(1)\n            x = target[t] if random.random() < teacher_forcing_ratio else pred\n\n        return outputs\n\n    def step(self, batch):\n        inputs, targets = batch['inputs'], batch['outputs']\n        inputs = inputs.transpose(0, 1)\n        targets = targets.transpose(0, 1)\n\n        output = self(inputs, targets)\n        output_dim = output.shape[-1]\n\n        output = output.reshape(-1, output_dim)\n        targets = targets.reshape(-1)\n        \n        return (output, targets)\n    \n    def training_step(self, batch):\n        loss = self.criterion(*self.step(batch))\n        self.log('train_loss', loss, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch):\n        loss = self.criterion(*self.step(batch))\n        self.log('val_loss', loss, prog_bar=True)\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=LR)\n\nmodel = Seq2Seq(len(token2id), EMBEDDING_DIM, HIDDEN_DIM, len(token2id), NUM_LAYERS, BIDIRECTIONAL, DROPOUT)\n\ntrain_dataloader = DataLoader(ds_splits['train'], batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2)\nval_dataloader = DataLoader(ds_splits['valid'], batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)\ntest_dataloader = DataLoader(ds_splits['test'], batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:11:24.497821Z","iopub.execute_input":"2024-02-13T18:11:24.498595Z","iopub.status.idle":"2024-02-13T18:11:24.561768Z","shell.execute_reply.started":"2024-02-13T18:11:24.498552Z","shell.execute_reply":"2024-02-13T18:11:24.560938Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Train the model\ntrainer = pl.Trainer(max_epochs=EPOCHS)\ntrainer.fit(model, train_dataloader, val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:11:27.207217Z","iopub.execute_input":"2024-02-13T18:11:27.207842Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ba639dc8e346f6a083391148cc0005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"markdown","source":"# TEST\n","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\n\ntotal_distances = []\nfor batch in tqdm(test_dataloader):\n    _, distances_list = evaluate(batch = batch, _device = device, _print = False, _cycle = True, _training = False)\n    total_distances.extend(distances_list)\n\nprint(f\"Total sentences = {len(total_distances)}\")\nprint(f\"Average TEST distance = {np.mean(total_distances)}\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-13T18:04:21.670668Z","iopub.execute_input":"2024-02-13T18:04:21.671032Z","iopub.status.idle":"2024-02-13T18:04:27.067114Z","shell.execute_reply.started":"2024-02-13T18:04:21.670993Z","shell.execute_reply":"2024-02-13T18:04:27.066028Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"\n  0%|          | 0/38 [00:00<?, ?it/s]\u001b[A\n  3%|▎         | 1/38 [00:00<00:07,  4.74it/s]\u001b[A\n  5%|▌         | 2/38 [00:00<00:05,  6.03it/s]\u001b[A\n  8%|▊         | 3/38 [00:00<00:05,  6.96it/s]\u001b[A\n 11%|█         | 4/38 [00:00<00:05,  6.80it/s]\u001b[A\n 13%|█▎        | 5/38 [00:00<00:04,  6.72it/s]\u001b[A\n 16%|█▌        | 6/38 [00:00<00:04,  6.98it/s]\u001b[A\n 18%|█▊        | 7/38 [00:01<00:04,  7.10it/s]\u001b[A\n 21%|██        | 8/38 [00:01<00:04,  7.25it/s]\u001b[A\n 24%|██▎       | 9/38 [00:01<00:04,  7.22it/s]\u001b[A\n 26%|██▋       | 10/38 [00:01<00:03,  7.32it/s]\u001b[A\n 29%|██▉       | 11/38 [00:01<00:03,  7.32it/s]\u001b[A\n 32%|███▏      | 12/38 [00:01<00:03,  6.95it/s]\u001b[A\n 34%|███▍      | 13/38 [00:01<00:03,  7.17it/s]\u001b[A\n 37%|███▋      | 14/38 [00:02<00:03,  6.78it/s]\u001b[A\n 39%|███▉      | 15/38 [00:02<00:03,  6.94it/s]\u001b[A\n 42%|████▏     | 16/38 [00:02<00:03,  6.70it/s]\u001b[A\n 45%|████▍     | 17/38 [00:02<00:03,  6.99it/s]\u001b[A\n 47%|████▋     | 18/38 [00:02<00:02,  7.10it/s]\u001b[A\n 50%|█████     | 19/38 [00:02<00:02,  7.12it/s]\u001b[A\n 53%|█████▎    | 20/38 [00:02<00:02,  7.41it/s]\u001b[A\n 55%|█████▌    | 21/38 [00:03<00:02,  7.14it/s]\u001b[A\n 58%|█████▊    | 22/38 [00:03<00:02,  7.38it/s]\u001b[A\n 61%|██████    | 23/38 [00:03<00:02,  7.40it/s]\u001b[A\n 63%|██████▎   | 24/38 [00:03<00:01,  7.36it/s]\u001b[A\n 66%|██████▌   | 25/38 [00:03<00:01,  7.39it/s]\u001b[A\n 68%|██████▊   | 26/38 [00:03<00:01,  7.43it/s]\u001b[A\n 71%|███████   | 27/38 [00:03<00:01,  7.21it/s]\u001b[A\n 74%|███████▎  | 28/38 [00:03<00:01,  7.28it/s]\u001b[A\n 76%|███████▋  | 29/38 [00:04<00:01,  6.99it/s]\u001b[A\n 79%|███████▉  | 30/38 [00:04<00:01,  6.96it/s]\u001b[A\n 82%|████████▏ | 31/38 [00:04<00:00,  7.14it/s]\u001b[A\n 84%|████████▍ | 32/38 [00:04<00:00,  7.14it/s]\u001b[A\n 87%|████████▋ | 33/38 [00:04<00:00,  7.16it/s]\u001b[A\n 89%|████████▉ | 34/38 [00:04<00:00,  7.27it/s]\u001b[A\n 92%|█████████▏| 35/38 [00:04<00:00,  7.38it/s]\u001b[A\n 95%|█████████▍| 36/38 [00:05<00:00,  6.71it/s]\u001b[A\n 97%|█████████▋| 37/38 [00:05<00:00,  6.94it/s]\u001b[A\n100%|██████████| 38/38 [00:05<00:00,  7.06it/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"Total sentences = 1200\nAverage TEST distance = 59.33833333333333\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}